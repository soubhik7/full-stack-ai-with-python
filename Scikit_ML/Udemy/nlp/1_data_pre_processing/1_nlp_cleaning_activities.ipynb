{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de01a0f",
   "metadata": {},
   "source": [
    "# Lowercase\n",
    "\n",
    "An important first step in working with text data is simply converting it into lowercase. Why do we do this? Well, it helps maintain consistency in our data and our output. When we're working with text, be that exploratory analysis or machine learning, we want to ensure words are understood and counted as the same word, your model might treat a word with a capital letter different from the same word  without any capital letter. Lowercasing ensures conformity.\n",
    "\n",
    "It also make it easier to continue with additonal cleaning of the data as we donâ€™t have to account for different cases.\n",
    "\n",
    "However, do remember that lowercasing can change the meaning of some text e.g \"US\" in uppercase is understood as a country, as opposed to \"us\".\n",
    "\n",
    "Let's take a look at how easy it is to convert our data to lowercase using python's built in lower() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3d85c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is soubhik\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My Name is Soubhik\"\n",
    "lowercase_sentence = sentence.lower()\n",
    "print(lowercase_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876af34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my name is soubhik', 'i live in india']\n"
     ]
    }
   ],
   "source": [
    "sentence_list = [\"My Name is Soubhik\", \"I live in India\"]\n",
    "lowercase_sentences = [x.lower() for x in sentence_list]\n",
    "print(lowercase_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67b0ac",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "\n",
    "In this lesson we'll be using the nltk package to remove stop words from text.\n",
    "\n",
    "Stop words are common words in the language which don't carry much meaning e.g. \"and\", \"of\", \"a\", \"to\".\n",
    "\n",
    "We remove these words because it removes a lot of complexity from the data. These words don't add much meaning to text so by removing them we are left with a smaller, cleaner dataset. Smaller, cleaner datasets often lead to increased accuracy in machine learning and will also speed up processing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad3cc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/soubhik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words. example : and, to, in, the, of, a, an, is, this > use Naural Language Toolkit (nltk) library\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "print(english_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf08c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sentence, showing stop words filtration.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a sample sentence, not showing off the stop words filtration.\"\n",
    "sentence_no_stopwords = ' '.join([word for word in sentence.split() if word.lower() not in english_stopwords])\n",
    "print(sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362bfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords.remove('did')\n",
    "english_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed29422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sentence, not showing stop words filtration.\n"
     ]
    }
   ],
   "source": [
    "english_stopwords.append('go')\n",
    "sentence_no_stopwords_custom = ' '.join([word for word in sentence.split() if word.lower() not in english_stopwords])\n",
    "print(sentence_no_stopwords_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3325e",
   "metadata": {},
   "source": [
    "# Regular Expressions\n",
    "\n",
    "Regular expressions, or \"regex\" for short, is a special syntax for searching for strings that meets a specified pattern. It's a great tool to filter and sort through text when you want to match patterns rather than a hard coded string or strings.\n",
    "\n",
    "There are loads of options for the syntax so it's best to just jump in and get started with some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7256e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f81f3",
   "metadata": {},
   "source": [
    "# Raw Strings\n",
    "\n",
    "Python recognises certain characters to have a special meaning, for example, \\n in python is used to indicate a new line. However, sometimes these codes that python recognises to have certain meanings appear in our strings and we want to tell python that a \\n in our text is a literal \\n, rather than meaning a new line.\n",
    "\n",
    "We can use the 'r' character before strings to indicate to python that our text is what is known as a \"raw string\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e6b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\my_data\\notes\n"
     ]
    }
   ],
   "source": [
    "my_folder = r\"C:\\my_data\\notes\"\n",
    "print(my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4cbdd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(22, 29), match='pattern'>\n"
     ]
    }
   ],
   "source": [
    "result_search = re.search(\"pattern\", r\"string to contain the pattern\")\n",
    "print(result_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10f58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "result_search = re.search(\"pattern\", r\"sample string without the special word\")\n",
    "print(result_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc089c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soubhik was able to help me find the items I needed quickly\n"
     ]
    }
   ],
   "source": [
    "string = r\"sara was able to help me find the items I needed quickly\"\n",
    "new_string = re.sub(r\"sara\", \"Soubhik\", string)\n",
    "print(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad81b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the cashier was very rude to him, I think her name was sara', 'I found everything I needed, thanks to the assistance from sara', 'sarah? and sam were both very helpful']\n"
     ]
    }
   ],
   "source": [
    "customer_review = [ \" sam was a great help to me in the store\", \"the cashier was very rude to him, I think her name was sara\", \"I found everything I needed, thanks to the assistance from sara\", \"amazing work from sadeen!\", \"not happy with the service, will not come back!\" , \"sarah? and sam were both very helpful\", \"i had to wait too long for assistance want\" ]\n",
    "\n",
    "sarahs_reviews = []\n",
    "\n",
    "pattern_to_find = r\"sarah?\"\n",
    "\n",
    "for string in customer_review:\n",
    "    if re.search(pattern_to_find, string):\n",
    "        sarahs_reviews.append(string)\n",
    "\n",
    "print(sarahs_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0135af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing work from sadeen!']\n"
     ]
    }
   ],
   "source": [
    "a_review = []\n",
    "pattern_to_find = r\"^a\"\n",
    "\n",
    "for string in customer_review:\n",
    "    if re.search(pattern_to_find, string):\n",
    "        a_review.append(string)\n",
    "print(a_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09136c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "y_review = []\n",
    "pattern_to_find = r\"y$\"\n",
    "\n",
    "for string in customer_review:\n",
    "    if re.search(pattern_to_find, string):\n",
    "        y_review.append(string)\n",
    "print(y_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266398bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I found everything I needed, thanks to the assistance from sara', 'i had to wait too long for assistance want']\n"
     ]
    }
   ],
   "source": [
    "needwant_reviews = []\n",
    "pattern_to_find = r\"\\b(need|want)(s|ed)?\\b\"\n",
    "\n",
    "for string in customer_review:\n",
    "    if re.search(pattern_to_find, string):\n",
    "        needwant_reviews.append(string)\n",
    "print(needwant_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0821c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' sam was a great help to me in the store', 'the cashier was very rude to him I think her name was sara', 'I found everything I needed thanks to the assistance from sara', 'amazing work from sadeen', 'not happy with the service will not come back', 'sarah and sam were both very helpful', 'i had to wait too long for assistance want']\n"
     ]
    }
   ],
   "source": [
    "no_punctuation_reviews = []\n",
    "pattern_to_find = r\"[^\\w\\s]\"\n",
    "for string in customer_review:\n",
    "    no_punct_string = re.sub(pattern_to_find, \"\", string)\n",
    "    no_punctuation_reviews.append(no_punct_string)\n",
    "print(no_punctuation_reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Python Kernel (3.12)",
   "language": "python",
   "name": "ai_python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
