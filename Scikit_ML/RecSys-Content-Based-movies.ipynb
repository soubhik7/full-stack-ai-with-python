{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dab0c74e-f6d5-4af0-9ce1-c149baa2b4d3",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "# Content Based Filtering\n",
        "\n",
        "\n",
        "Estimated time needed: **25** minutes\n",
        "    \n",
        "\n",
        "## Objectives\n",
        "\n",
        "After completing this lab you will be able to:\n",
        "\n",
        "* Create a recommendation system using Content Based filtering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2132789f-3bbb-4972-89f8-dda0d5b75a03",
      "metadata": {},
      "source": [
        "Recommendation systems are a collection of algorithms used to recommend items to users based on information taken from the user. These systems have become ubiquitous, and can be commonly seen in online stores, movies databases and job finders. In this notebook, we will explore Content-based recommendation systems and implement a simple version of one using Python and the Pandas library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6ea518-d8c7-42dc-a277-4848b0e0d87d",
      "metadata": {},
      "source": [
        "### Table of contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <ol>\n",
        "        <li><a href=\"#ref1\">Acquiring the Data</a></li>\n",
        "        <li><a href=\"#ref2\">Preprocessing</a></li>\n",
        "        <li><a href=\"#ref3\">Content-Based Filtering</a></li>\n",
        "    </ol>\n",
        "</div>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6ec480-64a2-4fcb-a952-7ea50ceb407c",
      "metadata": {},
      "source": [
        "<a id=\"ref1\"></a>\n",
        "# Acquiring the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7e49cd-2da7-4c4c-b5de-0c7f31cea2aa",
      "metadata": {},
      "source": [
        "To acquire and extract the data, simply run the following Bash scripts:  \n",
        "Dataset acquired from [GroupLens](http://grouplens.org/datasets/movielens/). Let's download the dataset. To download the data, we will use **`!wget`** to download it from Sample Object Storage.  \n",
        "__Did you know?__ When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? Sample is offering a unique opportunity for businesses, with 10 Tb of Sample Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-Sample-Offer-CC)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "97428438-51c8-4dd8-9795-c8bf0915cfc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "unziping ...\n",
            "unzip:  cannot find or open moviedataset.zip, moviedataset.zip.zip or moviedataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!wget -O moviedataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/SampleDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/data/moviedataset.zip\n",
        "print('unziping ...')\n",
        "!unzip -o -j moviedataset.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fb57e3-75c8-451c-b3d7-3494bb05be09",
      "metadata": {},
      "source": [
        "Now you're ready to start working with the data!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ed49f6-26e6-40af-8174-b53a6541271b",
      "metadata": {},
      "source": [
        "<a id=\"ref2\"></a>\n",
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10bec0ce-b30f-4797-879f-b0045396dff3",
      "metadata": {},
      "source": [
        "First, let's get all of the imports out of the way:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cae806e4-4124-4b48-85a6-43af0260af6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataframe manipulation library\n",
        "import pandas as pd\n",
        "#Math functions, we'll only need the sqrt function so let's import only that\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae8c6f05-de85-4529-9b77-c7d098ad6433",
      "metadata": {},
      "source": [
        "Now let's read each file into their Dataframes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f1e29867-76ab-4495-b209-4f1bbc90f0af",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'movies.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Storing the movie information into a pandas dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m movies_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmovies.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#Storing the user information into a pandas dataframe\u001b[39;00m\n\u001b[32m      4\u001b[39m ratings_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mratings.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/full-stack-ai-with-python/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/full-stack-ai-with-python/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/full-stack-ai-with-python/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/full-stack-ai-with-python/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/full-stack-ai-with-python/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'movies.csv'"
          ]
        }
      ],
      "source": [
        "#Storing the movie information into a pandas dataframe\n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "#Storing the user information into a pandas dataframe\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "#Head is a function that gets the first N rows of a dataframe. N's default is 5.\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba32db1-8dea-47fe-a20b-fe9076594ad3",
      "metadata": {},
      "source": [
        "Let's also remove the year from the __title__ column by using pandas' replace function and store in a new __year__ column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5841920-7575-4f0e-afae-375ae5c78749",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Using regular expressions to find a year stored between parentheses\n",
        "#We specify the parantheses so we don't conflict with movies that have years in their titles\n",
        "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
        "#Removing the parentheses\n",
        "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
        "#Removing the years from the 'title' column\n",
        "movies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n",
        "#Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
        "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118d7a9e-5164-490f-bd7b-972b213ece66",
      "metadata": {},
      "source": [
        "With that, let's also split the values in the __Genres__ column into a __list of Genres__ to simplify for future use. This can be achieved by applying Python's split string function on the correct column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "980dab43-c65f-4022-ab54-9550dd73cad6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Every genre is separated by a | so we simply have to call the split function on |\n",
        "movies_df['genres'] = movies_df.genres.str.split('|')\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be51cb66-69eb-40b3-9a85-ea301019ccbb",
      "metadata": {},
      "source": [
        "Since keeping genres in a list format isn't optimal for the content-based recommendation system technique, we will use the One Hot Encoding technique to convert the list of genres to a vector where each column corresponds to one possible value of the feature. This encoding is needed for feeding categorical data. In this case, we store every different genre in columns that contain either 1 or 0. 1 shows that a movie has that genre and 0 shows that it doesn't. Let's also store this dataframe in another variable since genres won't be important for our first recommendation system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f06dc08-baa0-4a9d-a1d6-f96a03f4345a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.\n",
        "moviesWithGenres_df = movies_df.copy()\n",
        "\n",
        "#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column\n",
        "for index, row in movies_df.iterrows():\n",
        "    for genre in row['genres']:\n",
        "        moviesWithGenres_df.at[index, genre] = 1\n",
        "#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\n",
        "moviesWithGenres_df = moviesWithGenres_df.fillna(0)\n",
        "moviesWithGenres_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a4653a-3e11-48d1-ac42-292903ada8fe",
      "metadata": {},
      "source": [
        "Next, let's look at the ratings dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c57b591-da4c-4497-8a5a-a22643b5bc89",
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4671f282-ba7b-4725-8413-d053d50192b7",
      "metadata": {},
      "source": [
        "Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the timestamp column, so let's drop it to save memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b9626e-4f2f-42da-aeca-210b6f9ab302",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Drop removes a specified row or column from a dataframe\n",
        "ratings_df = ratings_df.drop('timestamp', 1)\n",
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f11a42-a04d-4f80-854a-97f15f6d6a01",
      "metadata": {},
      "source": [
        "<a id=\"ref3\"></a>\n",
        "# Content-Based recommendation system\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "753163ef-295c-4119-a8a9-596cadd01bd8",
      "metadata": {},
      "source": [
        "Now, let's take a look at how to implement __Content-Based__ or __Item-Item recommendation systems__. This technique attempts to figure out what a user's favourite aspects of an item is, and then recommends items that present those aspects. In our case, we're going to try to figure out the input's favorite genres from the movies and ratings given.\n",
        "\n",
        "Let's begin by creating an input user to recommend movies to:\n",
        "\n",
        "Notice: To add more movies, simply increase the amount of elements in the __userInput__. Feel free to add more in! Just be sure to write it in with capital letters and if a movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The' .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f8c21c-50a0-4753-b96a-146b7c5a86ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "userInput = [\n",
        "            {'title':'Breakfast Club, The', 'rating':5},\n",
        "            {'title':'Toy Story', 'rating':3.5},\n",
        "            {'title':'Jumanji', 'rating':2},\n",
        "            {'title':\"Pulp Fiction\", 'rating':5},\n",
        "            {'title':'Akira', 'rating':4.5}\n",
        "         ] \n",
        "inputMovies = pd.DataFrame(userInput)\n",
        "inputMovies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741becef-8fd4-4a95-8f34-5a402fe19354",
      "metadata": {},
      "source": [
        "#### Add movieId to input user\n",
        "With the input complete, let's extract the input movie's ID's from the movies dataframe and add them into it.\n",
        "\n",
        "We can achieve this by first filtering out the rows that contain the input movie's title and then merging this subset with the input dataframe. We also drop unnecessary columns for the input to save memory space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2821b17a-4ff8-4142-af1c-8f76c6c447a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtering out the movies by title\n",
        "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
        "#Then merging it so we can get the movieId. It's implicitly merging it by title.\n",
        "inputMovies = pd.merge(inputId, inputMovies)\n",
        "#Dropping information we won't use from the input dataframe\n",
        "inputMovies = inputMovies.drop('genres', 1).drop('year', 1)\n",
        "#Final input dataframe\n",
        "#If a movie you added in above isn't here, then it might not be in the original \n",
        "#dataframe or it might spelled differently, please check capitalisation.\n",
        "inputMovies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54662bd7-68d9-4c2f-989c-7ff2c96cc7b6",
      "metadata": {},
      "source": [
        "We're going to start by learning the input's preferences, so let's get the subset of movies that the input has watched from the Dataframe containing genres defined with binary values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a17a4b0-9f45-4088-8ebb-59e24a4323f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filtering out the movies from the input\n",
        "userMovies = moviesWithGenres_df[moviesWithGenres_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
        "userMovies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff6c916-d49e-4ef4-9ec1-d8c570df7cd1",
      "metadata": {},
      "source": [
        "We'll only need the actual genre table, so let's clean this up a bit by resetting the index and dropping the movieId, title, genres and year columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5180f77b-0932-4f7a-aba1-51e14baa6cbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Resetting the index to avoid future issues\n",
        "userMovies = userMovies.reset_index(drop=True)\n",
        "#Dropping unnecessary issues due to save memory and to avoid issues\n",
        "userGenreTable = userMovies.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\n",
        "userGenreTable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52b929c-e67b-4899-8b2e-2ffb2ae83e8f",
      "metadata": {},
      "source": [
        "Now we're ready to start learning the input's preferences!\n",
        "\n",
        "To do this, we're going to turn each genre into weights. We can do this by using the input's reviews and multiplying them into the input's genre table and then summing up the resulting table by column. This operation is actually a dot product between a matrix and a vector, so we can simply accomplish by calling the Pandas \"dot\" function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0c3c32-97ad-4add-9e57-40f3a6bc21a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "inputMovies['rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619aeded-d0dc-48d4-bd31-ca86c9454622",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dot produt to get weights\n",
        "userProfile = userGenreTable.transpose().dot(inputMovies['rating'])\n",
        "#The user profile\n",
        "userProfile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc8cf1c-41b3-4b5c-9a11-643073106d16",
      "metadata": {},
      "source": [
        "Now, we have the weights for every of the user's preferences. This is known as the User Profile. Using this, we can recommend movies that satisfy the user's preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d1a3cfd-2c3b-4795-9b08-ebfb2443dac0",
      "metadata": {},
      "source": [
        "Let's start by extracting the genre table from the original dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bff9afd-4e66-47a9-9d60-a04d62de0973",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Now let's get the genres of every movie in our original dataframe\n",
        "genreTable = moviesWithGenres_df.set_index(moviesWithGenres_df['movieId'])\n",
        "#And drop the unnecessary information\n",
        "genreTable = genreTable.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\n",
        "genreTable.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2eb2bfb-f087-439f-a536-13799ff685b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "genreTable.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d15ef680-98c0-4da9-8818-fd49eb3de70d",
      "metadata": {},
      "source": [
        "With the input's profile and the complete list of movies and their genres in hand, we're going to take the weighted average of every movie based on the input profile and recommend the top twenty movies that most satisfy it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f283b6-5164-4359-b89d-618be7a159f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Multiply the genres by the weights and then take the weighted average\n",
        "recommendationTable_df = ((genreTable*userProfile).sum(axis=1))/(userProfile.sum())\n",
        "recommendationTable_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae93f9e-2738-4581-b569-e6b2c9cfb7cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Sort our recommendations in descending order\n",
        "recommendationTable_df = recommendationTable_df.sort_values(ascending=False)\n",
        "#Just a peek at the values\n",
        "recommendationTable_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c04ea0d-4da8-48e0-88ee-cfd7149d30ca",
      "metadata": {},
      "source": [
        "Now here's the recommendation table!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d91f64-6782-44b6-9804-1bab9b15144a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#The final recommendation table\n",
        "movies_df.loc[movies_df['movieId'].isin(recommendationTable_df.head(20).keys())]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd3e82e4-2573-4718-933a-3b71a2791c9f",
      "metadata": {},
      "source": [
        "### Advantages and Disadvantages of Content-Based Filtering\n",
        "\n",
        "##### Advantages\n",
        "* Learns user's preferences\n",
        "* Highly personalized for the user\n",
        "\n",
        "##### Disadvantages\n",
        "* Doesn't take into account what others think of the item, so low quality item recommendations might happen\n",
        "* Extracting data is not always intuitive\n",
        "* Determining what characteristics of the item the user dislikes or likes is not always obvious\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393c5c56-48ab-40b8-9c91-f2f0283750d0",
      "metadata": {},
      "source": [
        "<h2>Want to learn more?</h2>\n",
        "\n",
        "Sample SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems â€“ by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"https://www.Sample.com/analytics/spss-statistics-software?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-SampleDeveloperSkillsNetwork-ML0101EN-SkillsNetwork\">SPSS Modeler</a>\n",
        "\n",
        "Also, you can use Sample Studio to run these notebooks faster with bigger datasets. Sample Studio is Sample's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Sample Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Sample Studio users today with a free account at <a href=\"https://www.Sample.com/cloud/Sample-studio?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-SampleDeveloperSkillsNetwork-ML0101EN-SkillsNetwork\">Sample Studio</a>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "AI Python Kernel (3.12)",
      "language": "python",
      "name": "ai_python_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "prev_pub_hash": "b5b85972d4f5eb7db7f566506fbbc694d61bf8a286a751e486938435c537a527"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
